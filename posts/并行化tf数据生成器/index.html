<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>并行化tf数据生成器 | Aida’s home</title>
<meta name="keywords" content="tensorflow">
<meta name="description" content="在处理大规模数据时，数据无法全部载入内存，我们通常用两个选项
使用tfrecords 使用 tf.data.Dataset.from_generator() tfrecords的并行化使用前文已经有过介绍，这里不再赘述。如果我们不想生成tfrecord中间文件，那么生成器就是你所需要的。
本文主要记录针对 from_generator()的并行化方法，在 tf.data 中，并行化主要通过 map和 num_parallel_calls 实现，但是对一些场景，我们的generator()中有一些处理逻辑，是无法直接并行化的，最简单的方法就是将generator()中的逻辑抽出来，使用map实现。
tf.data.Dataset generator 并行 对generator()中的复杂逻辑，我们对其进行简化，即仅在生成器中做一些下标取值的类型操作，将generator()中处理部分使用py_function 包裹(wrapped) ，然后调用map处理。
def func(i): i = i.numpy() # Decoding from the EagerTensor object x, y = your_processing_function(training_set[i]) return x, y z = list(range(len(training_set))) # The index generator dataset = tf.data.Dataset.from_generator(lambda: z, tf.uint8) dataset = dataset.map(lambda i: tf.py_function(func=func, inp=[i], Tout=[tf.uint8, tf.float32] ), num_parallel_calls=tf.data.AUTOTUNE) 由于隐式推断的原因，有时tensor的输出shape是未知的，需要额外处理
A Tensor&rsquo;s shape (that is, the rank of the Tensor and the size of each dimension) may not always be fully known.">
<meta name="author" content="Gongyan Zhou">
<link rel="canonical" href="https://aida-yy.github.io/posts/%E5%B9%B6%E8%A1%8C%E5%8C%96tf%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90%E5%99%A8/">
<meta name="yandex-verification" content="XYZabc">
<meta name="msvalidate.01" content="XYZabc">
<link crossorigin="anonymous" href="/assets/css/stylesheet.3299c596a7007118365635c056dd427dace22b7b8c1341fdef6fa6c31359ba10.css" integrity="" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.acb54fd32bbc1982428b8850317e45d076b95012730a5936667e6bc21777692a.js" integrity=""
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://aida-yy.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://aida-yy.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://aida-yy.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://aida-yy.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://aida-yy.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<meta property="og:title" content="并行化tf数据生成器" />
<meta property="og:description" content="在处理大规模数据时，数据无法全部载入内存，我们通常用两个选项
使用tfrecords 使用 tf.data.Dataset.from_generator() tfrecords的并行化使用前文已经有过介绍，这里不再赘述。如果我们不想生成tfrecord中间文件，那么生成器就是你所需要的。
本文主要记录针对 from_generator()的并行化方法，在 tf.data 中，并行化主要通过 map和 num_parallel_calls 实现，但是对一些场景，我们的generator()中有一些处理逻辑，是无法直接并行化的，最简单的方法就是将generator()中的逻辑抽出来，使用map实现。
tf.data.Dataset generator 并行 对generator()中的复杂逻辑，我们对其进行简化，即仅在生成器中做一些下标取值的类型操作，将generator()中处理部分使用py_function 包裹(wrapped) ，然后调用map处理。
def func(i): i = i.numpy() # Decoding from the EagerTensor object x, y = your_processing_function(training_set[i]) return x, y z = list(range(len(training_set))) # The index generator dataset = tf.data.Dataset.from_generator(lambda: z, tf.uint8) dataset = dataset.map(lambda i: tf.py_function(func=func, inp=[i], Tout=[tf.uint8, tf.float32] ), num_parallel_calls=tf.data.AUTOTUNE) 由于隐式推断的原因，有时tensor的输出shape是未知的，需要额外处理
A Tensor&rsquo;s shape (that is, the rank of the Tensor and the size of each dimension) may not always be fully known." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://aida-yy.github.io/posts/%E5%B9%B6%E8%A1%8C%E5%8C%96tf%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90%E5%99%A8/" /><meta property="og:image" content="https://aida-yy.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-08-20T11:30:03&#43;00:00" />
<meta property="article:modified_time" content="2022-08-20T11:30:03&#43;00:00" /><meta property="og:site_name" content="Aida’s home" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://aida-yy.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"/>

<meta name="twitter:title" content="并行化tf数据生成器"/>
<meta name="twitter:description" content="在处理大规模数据时，数据无法全部载入内存，我们通常用两个选项
使用tfrecords 使用 tf.data.Dataset.from_generator() tfrecords的并行化使用前文已经有过介绍，这里不再赘述。如果我们不想生成tfrecord中间文件，那么生成器就是你所需要的。
本文主要记录针对 from_generator()的并行化方法，在 tf.data 中，并行化主要通过 map和 num_parallel_calls 实现，但是对一些场景，我们的generator()中有一些处理逻辑，是无法直接并行化的，最简单的方法就是将generator()中的逻辑抽出来，使用map实现。
tf.data.Dataset generator 并行 对generator()中的复杂逻辑，我们对其进行简化，即仅在生成器中做一些下标取值的类型操作，将generator()中处理部分使用py_function 包裹(wrapped) ，然后调用map处理。
def func(i): i = i.numpy() # Decoding from the EagerTensor object x, y = your_processing_function(training_set[i]) return x, y z = list(range(len(training_set))) # The index generator dataset = tf.data.Dataset.from_generator(lambda: z, tf.uint8) dataset = dataset.map(lambda i: tf.py_function(func=func, inp=[i], Tout=[tf.uint8, tf.float32] ), num_parallel_calls=tf.data.AUTOTUNE) 由于隐式推断的原因，有时tensor的输出shape是未知的，需要额外处理
A Tensor&rsquo;s shape (that is, the rank of the Tensor and the size of each dimension) may not always be fully known."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://aida-yy.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "并行化tf数据生成器",
      "item": "https://aida-yy.github.io/posts/%E5%B9%B6%E8%A1%8C%E5%8C%96tf%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90%E5%99%A8/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "并行化tf数据生成器",
  "name": "并行化tf数据生成器",
  "description": "在处理大规模数据时，数据无法全部载入内存，我们通常用两个选项\n使用tfrecords 使用 tf.data.Dataset.from_generator() tfrecords的并行化使用前文已经有过介绍，这里不再赘述。如果我们不想生成tfrecord中间文件，那么生成器就是你所需要的。\n本文主要记录针对 from_generator()的并行化方法，在 tf.data 中，并行化主要通过 map和 num_parallel_calls 实现，但是对一些场景，我们的generator()中有一些处理逻辑，是无法直接并行化的，最简单的方法就是将generator()中的逻辑抽出来，使用map实现。\ntf.data.Dataset generator 并行 对generator()中的复杂逻辑，我们对其进行简化，即仅在生成器中做一些下标取值的类型操作，将generator()中处理部分使用py_function 包裹(wrapped) ，然后调用map处理。\ndef func(i): i = i.numpy() # Decoding from the EagerTensor object x, y = your_processing_function(training_set[i]) return x, y z = list(range(len(training_set))) # The index generator dataset = tf.data.Dataset.from_generator(lambda: z, tf.uint8) dataset = dataset.map(lambda i: tf.py_function(func=func, inp=[i], Tout=[tf.uint8, tf.float32] ), num_parallel_calls=tf.data.AUTOTUNE) 由于隐式推断的原因，有时tensor的输出shape是未知的，需要额外处理\nA Tensor\u0026rsquo;s shape (that is, the rank of the Tensor and the size of each dimension) may not always be fully known.",
  "keywords": [
    "tensorflow"
  ],
  "articleBody": "在处理大规模数据时，数据无法全部载入内存，我们通常用两个选项\n使用tfrecords 使用 tf.data.Dataset.from_generator() tfrecords的并行化使用前文已经有过介绍，这里不再赘述。如果我们不想生成tfrecord中间文件，那么生成器就是你所需要的。\n本文主要记录针对 from_generator()的并行化方法，在 tf.data 中，并行化主要通过 map和 num_parallel_calls 实现，但是对一些场景，我们的generator()中有一些处理逻辑，是无法直接并行化的，最简单的方法就是将generator()中的逻辑抽出来，使用map实现。\ntf.data.Dataset generator 并行 对generator()中的复杂逻辑，我们对其进行简化，即仅在生成器中做一些下标取值的类型操作，将generator()中处理部分使用py_function 包裹(wrapped) ，然后调用map处理。\ndef func(i): i = i.numpy() # Decoding from the EagerTensor object x, y = your_processing_function(training_set[i]) return x, y z = list(range(len(training_set))) # The index generator dataset = tf.data.Dataset.from_generator(lambda: z, tf.uint8) dataset = dataset.map(lambda i: tf.py_function(func=func, inp=[i], Tout=[tf.uint8, tf.float32] ), num_parallel_calls=tf.data.AUTOTUNE) 由于隐式推断的原因，有时tensor的输出shape是未知的，需要额外处理\nA Tensor’s shape (that is, the rank of the Tensor and the size of each dimension) may not always be fully known. In tf.function definitions, the shape may only be partially known.\nMost operations produce tensors of fully-known shapes if the shapes of their inputs are also fully known, but in some cases it’s only possible to find the shape of a tensor at execution time.\ndataset = dataset.batch(8)\rdef _fixup_shape(x, y):\rx.set_shape([None, None, None, nb_channels]) # n, h, w, c\ry.set_shape([None, nb_classes]) # n, nb_classes\rreturn x, y\rdataset = dataset.map(_fixup_shape) tf.Tensor与tf.EagerTensor 为什么需要 tf.py_function，先来看下tf.Tensor与tf.EagerTensor\nEagerTensor是实时的，可以在任何时候获取到它的值，即通过numpy获取\nTensor是非实时的，它是静态图中的组件，只有当喂入数据、运算完成才能获得该Tensor的值，\nmap中映射的函数运算，而仅仅是告诉dataset，你每一次拿出来的样本时要先进行一遍function运算之后才使用的，所以function的调用是在每次迭代dataset的时候才调用的，属于静态图逻辑\ntensorflow.python.framework.ops.EagerTensor\rtensorflow.python.framework.ops.Tensor tf.py_function在这里起了什么作用？\nWraps a python function into a TensorFlow op that executes it eagerly.\n刚才说到map数据静态图逻辑，默认参数都是Tensor。而 使用tf.py_function()包装后，参数就变成了EagerTensor。\nreferences 【1】https://medium.com/@acordier/tf-data-dataset-generators-with-parallelization-the-easy-way-b5c5f7d2a18\n【2】https://blog.csdn.net/qq_27825451/article/details/105247211\n【3】https://www.tensorflow.org/guide/data_performance#parallelizing_data_extraction\n",
  "wordCount" : "178",
  "inLanguage": "en",
  "datePublished": "2022-08-20T11:30:03Z",
  "dateModified": "2022-08-20T11:30:03Z",
  "author":{
    "@type": "Person",
    "name": "Gongyan Zhou"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://aida-yy.github.io/posts/%E5%B9%B6%E8%A1%8C%E5%8C%96tf%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90%E5%99%A8/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Aida’s home",
    "logo": {
      "@type": "ImageObject",
      "url": "https://aida-yy.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://aida-yy.github.io/" accesskey="h" title="Home (Alt + H)">Home</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://aida-yy.github.io/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://aida-yy.github.io/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
            <li>
                <a href="https://aida-yy.github.io/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
            <li>
                <a href="https://aida-yy.github.io/booklist/" title="书单">
                    <span>书单</span>
                </a>
            </li>
            <li>
                <a href="https://aida-yy.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://aida-yy.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://aida-yy.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      并行化tf数据生成器
    </h1>
    <div class="post-meta"><span title='2022-08-20 11:30:03 +0000 +0000'>August 20, 202020</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;178 words&nbsp;·&nbsp;Gongyan Zhou

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#references">references</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><p>在处理大规模数据时，数据无法全部载入内存，我们通常用两个选项</p>
<ul>
<li>使用<code>tfrecords</code></li>
<li>使用 <code>tf.data.Dataset.from_generator()</code></li>
</ul>
<p><a href="https://www.cnblogs.com/gongyanzh/p/16266794.html">tfrecords的并行化使用</a>前文已经有过介绍，这里不再赘述。如果我们不想生成tfrecord中间文件，那么生成器就是你所需要的。</p>
<p>本文主要记录针对 <code>from_generator()</code>的并行化方法，在 <code>tf.data</code> 中，并行化主要通过 <code>map</code>和 <code>num_parallel_calls</code> 实现，但是对一些场景，我们的<code>generator()</code>中有一些处理逻辑，是无法直接并行化的，最简单的方法就是将<code>generator()</code>中的逻辑抽出来，使用<code>map</code>实现。</p>
<h1 id="tfdatadataset-generator-并行">tf.data.Dataset generator 并行<a hidden class="anchor" aria-hidden="true" href="#tfdatadataset-generator-并行">#</a></h1>
<p>对<code>generator()</code>中的复杂逻辑，我们对其进行简化，即仅在生成器中做一些下标取值的类型操作，将<code>generator()</code>中处理部分使用<code>py_function </code> 包裹(wrapped) ，然后调用map处理。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># Decoding from the EagerTensor object</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">your_processing_function</span><span class="p">(</span><span class="n">training_set</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">z</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_set</span><span class="p">)))</span> <span class="c1"># The index generator</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_generator</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">z</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">py_function</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">func</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                               <span class="n">inp</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                                               <span class="n">Tout</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                     <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">                                               <span class="p">),</span> 
</span></span><span class="line"><span class="cl">                      <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
</span></span></code></pre></div><p>由于隐式推断的原因，有时tensor的输出shape是未知的，需要额外处理</p>
<blockquote>
<p>A Tensor&rsquo;s shape (that is, the rank of the Tensor and the size of each dimension) may not always be fully known. In <a href="https://www.tensorflow.org/api_docs/python/tf/function"><code>tf.function</code></a> definitions, the shape may only be partially known.</p>
<p>Most operations produce tensors of fully-known shapes if the shapes of their inputs are also fully known, but in some cases it&rsquo;s only possible to find the shape of a tensor at execution time.</p>
</blockquote>
<pre tabindex="0"><code>dataset = dataset.batch(8)
def _fixup_shape(x, y):
    x.set_shape([None, None, None, nb_channels]) # n, h, w, c
    y.set_shape([None, nb_classes]) # n, nb_classes
    return x, y
dataset = dataset.map(_fixup_shape)
</code></pre><h1 id="tftensor与tfeagertensor">tf.Tensor与tf.EagerTensor<a hidden class="anchor" aria-hidden="true" href="#tftensor与tfeagertensor">#</a></h1>
<p><strong>为什么需要 <code>tf.py_function</code>，先来看下<code>tf.Tensor</code>与<code>tf.EagerTensor</code></strong></p>
<p>EagerTensor是实时的，可以在任何时候获取到它的值，即通过numpy获取</p>
<p>Tensor是非实时的，它是静态图中的组件，只有当喂入数据、运算完成才能获得该Tensor的值，</p>
<blockquote>
<p>map中映射的函数运算，而仅仅是告诉dataset，你每一次拿出来的样本时要先进行一遍function运算之后才使用的，所以function的调用是在每次迭代dataset的时候才调用的，属于<strong>静态图逻辑</strong></p>
</blockquote>
<pre tabindex="0"><code>tensorflow.python.framework.ops.EagerTensor
tensorflow.python.framework.ops.Tensor
</code></pre><p><strong><code>tf.py_function</code>在这里起了什么作用？</strong></p>
<blockquote>
<p>Wraps a python function into a TensorFlow op that executes it eagerly.</p>
</blockquote>
<p>刚才说到map数据静态图逻辑，默认参数都是Tensor。而 使用<code>tf.py_function()</code>包装后，参数就变成了EagerTensor。</p>
<h3 id="references">references<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h3>
<p>【1】https://medium.com/@acordier/tf-data-dataset-generators-with-parallelization-the-easy-way-b5c5f7d2a18</p>
<p>【2】https://blog.csdn.net/qq_27825451/article/details/105247211</p>
<p>【3】https://www.tensorflow.org/guide/data_performance#parallelizing_data_extraction</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://aida-yy.github.io/tags/tensorflow/">tensorflow</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://aida-yy.github.io/posts/docker/">
    <span class="title">« Prev</span>
    <br>
    <span>docker快速上手</span>
  </a>
  <a class="next" href="https://aida-yy.github.io/posts/%E6%A8%A1%E5%9E%8B%E5%8F%AC%E5%9B%9E%E4%B9%8Bdssm/">
    <span class="title">Next »</span>
    <br>
    <span>模型召回之DSSM</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share 并行化tf数据生成器 on twitter"
        href="https://twitter.com/intent/tweet/?text=%e5%b9%b6%e8%a1%8c%e5%8c%96tf%e6%95%b0%e6%8d%ae%e7%94%9f%e6%88%90%e5%99%a8&amp;url=https%3a%2f%2faida-yy.github.io%2fposts%2f%25E5%25B9%25B6%25E8%25A1%258C%25E5%258C%2596tf%25E6%2595%25B0%25E6%258D%25AE%25E7%2594%259F%25E6%2588%2590%25E5%2599%25A8%2f&amp;hashtags=tensorflow">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 并行化tf数据生成器 on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2faida-yy.github.io%2fposts%2f%25E5%25B9%25B6%25E8%25A1%258C%25E5%258C%2596tf%25E6%2595%25B0%25E6%258D%25AE%25E7%2594%259F%25E6%2588%2590%25E5%2599%25A8%2f&amp;title=%e5%b9%b6%e8%a1%8c%e5%8c%96tf%e6%95%b0%e6%8d%ae%e7%94%9f%e6%88%90%e5%99%a8&amp;summary=%e5%b9%b6%e8%a1%8c%e5%8c%96tf%e6%95%b0%e6%8d%ae%e7%94%9f%e6%88%90%e5%99%a8&amp;source=https%3a%2f%2faida-yy.github.io%2fposts%2f%25E5%25B9%25B6%25E8%25A1%258C%25E5%258C%2596tf%25E6%2595%25B0%25E6%258D%25AE%25E7%2594%259F%25E6%2588%2590%25E5%2599%25A8%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 并行化tf数据生成器 on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2faida-yy.github.io%2fposts%2f%25E5%25B9%25B6%25E8%25A1%258C%25E5%258C%2596tf%25E6%2595%25B0%25E6%258D%25AE%25E7%2594%259F%25E6%2588%2590%25E5%2599%25A8%2f&title=%e5%b9%b6%e8%a1%8c%e5%8c%96tf%e6%95%b0%e6%8d%ae%e7%94%9f%e6%88%90%e5%99%a8">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 并行化tf数据生成器 on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2faida-yy.github.io%2fposts%2f%25E5%25B9%25B6%25E8%25A1%258C%25E5%258C%2596tf%25E6%2595%25B0%25E6%258D%25AE%25E7%2594%259F%25E6%2588%2590%25E5%2599%25A8%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 并行化tf数据生成器 on whatsapp"
        href="https://api.whatsapp.com/send?text=%e5%b9%b6%e8%a1%8c%e5%8c%96tf%e6%95%b0%e6%8d%ae%e7%94%9f%e6%88%90%e5%99%a8%20-%20https%3a%2f%2faida-yy.github.io%2fposts%2f%25E5%25B9%25B6%25E8%25A1%258C%25E5%258C%2596tf%25E6%2595%25B0%25E6%258D%25AE%25E7%2594%259F%25E6%2588%2590%25E5%2599%25A8%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 并行化tf数据生成器 on telegram"
        href="https://telegram.me/share/url?text=%e5%b9%b6%e8%a1%8c%e5%8c%96tf%e6%95%b0%e6%8d%ae%e7%94%9f%e6%88%90%e5%99%a8&amp;url=https%3a%2f%2faida-yy.github.io%2fposts%2f%25E5%25B9%25B6%25E8%25A1%258C%25E5%258C%2596tf%25E6%2595%25B0%25E6%258D%25AE%25E7%2594%259F%25E6%2588%2590%25E5%2599%25A8%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://aida-yy.github.io/">Aida’s home</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
